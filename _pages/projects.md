---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
---

{% include base_path %}


Publically funded projects: [JSPS KAKEN](https://nrid.nii.ac.jp/en/nrid/1000060913910/){:target="_blank"}, [research-er.jp](https://research-er.jp/researchers/view/992994){:target="_blank"}


<!---  New html page  -->
<table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr bgcolor="#ffffd0">
      <td style="padding:16px;width:30%;vertical-align:middle">
          <img src="/images/coderunner-agent.png" width="100%">
      </td>
      <td style="padding:8px;width:70%;vertical-align:middle">
        <h2>
	  <a href="https://li-huiyong.github.io/MetaStep">
            <span style="font-weight: bold;">
	      MetaStep: Large Language Model-based Metacognitive Scaffolding in Introductory Programming Education
	    </span>
	  </a>
        </h2>
        <p>
	  JSPS Grant-in-Aid for Early-Career Scientists <a href="https://kaken.nii.ac.jp/ja/grant/KAKENHI-PROJECT-25K17078/">(25K17078)</a>
	</p>
        <p>
	  2025-04-01 – 2028-03-31
	</p>
        <a href="https://li-huiyong.github.io/MetaStep">Project Page</a>
	|
        <a href="https://doi.org/10.48550/arXiv.2504.03068">arxiv</a>
        | Code
        <p></p>
        <p>
This project aims to develop MetaStep, an LLM-based support system designed to promote self-regulated learning in introductory programming education. By seamlessly integrating students’ cognitive and metacognitive models into LLM-based scaffolding, MetaStep enables a gradual transfer of regulatory control from AI to students, supporting their development into self-directed learners.
        </p>
      </td>
</tr>

<tr bgcolor="#ffffd0">
      <td style="padding:16px;width:30%;vertical-align:middle">
          <img src="/images/mixai-learn.png" width="100%">
      </td>
      <td style="padding:8px;width:70%;vertical-align:middle">
        <h2>
	  <a href="https://sites.google.com/view/mixailearn/home">
            <span style="font-weight: bold;">
	      miXai^learn: Multimodal Interactions, and Explainable AI for Embodied learning
	    </span>
	  </a>
        </h2>
        <p>
	  JSPS Fund for the Promotion of Joint International Research (International Collaborative Research) <a href="https://kaken.nii.ac.jp/en/grant/KAKENHI-PROJECT-24KK0051/">(24KK0051)</a>
	</p>
        <p>
	  2024-09-09 – 2027-03-31
	</p>
        <a href="https://sites.google.com/view/mixailearn/home">Project Page</a>
        <p></p>
        <p>
This joint research takes the standpoint that learning has embodied experiences distributed in the physical and virtual spaces. While current online learning systems often focus on the cognitive skills, there is a lack of data-driven approaches for tracking learning process and provide feedback on tasks that are distributed in physical and virtual spaces. This research explores an innovative integration of Artificial Intelligence (AI) and socially assistive robotics in a technical infrastructure to enhance learner’s critical reflection in the psychomotor and cognitive aspects of learning.
        </p>
      </td>
</tr>

 <tr bgcolor="#f8f4ed">
      <td style="padding:16px;width:30%;vertical-align:middle">
          <img src="/images/mmlair.png" width="100%">
      </td>
      <td style="padding:8px;width:70%;vertical-align:middle">
        <h2>
	  <a href="https://li-huiyong.github.io/MMLAIR">
            <span style="font-weight: bold;">MMLAIR: Multimodal Learning Analytics in Reading</span>
	  </a>
        </h2>
        <p>
	  Education and Research Support Program on Mathematical and Data Science (Kyushu University)
	</p>
        <p>
	  2024-06-18 – 2025-03-31
	</p>
        <a href="https://li-huiyong.github.io/MMLAIR">Project Page</a>
        <p></p>
        <p>
This project analyzes students' behavioral, cognitive, and emotional patterns during digital reading to understand learning processes and predict knowledge outcomes. By continuously monitoring multimodal data from learning logs, eye-tracking, and physiological sensors, the research enables adaptive learning systems that respond dynamically to individual student states, supporting personalized educational interventions in real-time.
        </p>
      </td>
</tr>

<tr bgcolor="#f8f4ed">
      <td style="padding:16px;width:30%;vertical-align:middle">
          <img src="/images/goal-logo.png" style="align: center; width: 75%">
      </td>
      <td style="padding:8px;width:70%;vertical-align:middle">
        <h2>
	  <a href="https://sites.google.com/view/letsgoal">
            <span style="font-weight: bold;">
	      GOAL project: AI-supported self-directed learning lifestyle in data-rich educational ecosystem
	    </span>
	  </a>
        </h2>
        <p>
	  JSPS Grant-in-Aid for Scientific Research (B) <a href="https://kaken.nii.ac.jp/ja/grant/KAKENHI-PROJECT-23K25156/">(23K25156)</a>
	</p>
        <p>
	  2022-04-01 – 2025-03-31
	</p>
        <a href="https://sites.google.com/view/letsgoal">Project Page</a>
	|
        <a href="https://sites.google.com/view/letsgoal/publication">Publications</a>
        <p></p>
        <p>
Learners need to be trained to be self-directed in their learning and daily activities. This research focuses on developing digital learning environments that trace learners' behaviors and provide them functionalities to develop such self-direction skills by analysis of those data.
        </p>
      </td>
</tr>

<tr bgcolor="#f8f4ed">
      <td style="padding:16px;width:30%;vertical-align:middle;">
          <img src="/images/sip2-leaf.png" width="100%">
      </td>
      <td style="padding:8px;width:70%;vertical-align:middle">
        <h2>
	  <a href="https://www.let.media.kyoto-u.ac.jp/en/project/sip/">
            <span style="font-weight: bold;">
	      Cyberspace Infrastructure Technology Using Big Data and AI: Research on Evidence-Based Tailor-Made Education
	    </span>
	  </a>
        </h2>
        <p>
	  The Second Phase of Cross-ministerial Strategic Innovation Promotion Program (SIP2) <a href="https://www.nedo.go.jp/activities/ZZJP2_100126.html">(JPNP18013)</a>
	</p>
        <p>
	  2018-11-15 - 2023-03-31
	</p>
        <a href="https://www.let.media.kyoto-u.ac.jp/en/project/sip/">Project Page</a>
	|
        <a href="https://www8.cao.go.jp/cstp/gaiyo/sip/sip2_seika/big3.pdf">Final Report in JP (p.31-36)</a>
        <p></p>
        <p>
In this research, we collect and analyze learning data logs which is otherwise difficult to synthesize automatically and requires advanced interaction tracking. The approach consumes the domain knowledge of learning and cognitive science, artificial intelligence, and information and communication infrastructure technology. By researching and developing the AI driven pedagogical platform, we aim to realize a precision education that can be tailored to the characteristics of learners based on evidence.
        </p>
      </td>
</tr>

</tbody></table>

